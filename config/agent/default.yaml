save_dir: "./trained_models"
save_replay_buffer: ${save_replay_buffer}
train_mean_n_ep: 10  # Compute the mean over train_mean_n_ep episodes to log
hyperparameters:
    gamma: 0.99
    actor_lr: 3e-4
    critic_lr: 3e-4
    alpha_lr: 3e-4
    alpha: "auto" #"auto",
    tau: 0.005
    batch_size: 256
    buffer_size: 1e5
    learning_starts: 1000 # timesteps before starting updates
    init_temp: 0.01 # Initialization of entropy coeficient

net_cfg:
    hidden_dim: 256
    latent_dim: 16
    activation: relu
    n_layers: 4
    affordance: ${affordance}
    actor_net: CNNPolicyDenseNet
    critic_net: CNNCriticDenseNet

learn_config:
    total_timesteps: 400000
    log_interval: 4000 # log timestep mean_eval reward every log_interval steps
    full_eval_interval: 16000
    max_episode_length: 100 #max episode length
    n_eval_ep: 5